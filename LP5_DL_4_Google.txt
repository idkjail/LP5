import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import math
from keras.models import Sequential
from keras.layers import Dense, SimpleRNN, Dropout

# Load and inspect data
data = pd.read_csv('GOOG.csv', parse_dates=['Date'])
print(data.tail())
print(data.columns)
print(data.dtypes)
print(data.describe())
print(data.isnull().sum())

# Drop non-numeric columns like 'Date' for correlation
numeric_data = data.drop(columns=['Date'])
plt.figure(figsize=(10,6))
corr_matrix = numeric_data.corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title('Feature Correlation Matrix')
plt.show()

# Split data into training and testing sets
data_training = data[data['Date']<'2019-01-01'].copy()
data_test = data[data['Date']>='2019-01-01'].copy()

# Drop unused columns and scale
training_set = data_training.drop(['Date', 'Adj Close'], axis=1)
scaler = MinMaxScaler()
data_training_scaled = scaler.fit_transform(training_set)

# Create training data with 60 timesteps
X_train = []
y_train = []
for i in range(60, data_training_scaled.shape[0]):
    X_train.append(data_training_scaled[i-60:i])
    y_train.append(data_training_scaled[i, 0])
X_train, y_train = np.array(X_train), np.array(y_train)

# Build RNN model
regressor = Sequential()
regressor.add(SimpleRNN(units=50, activation='tanh', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
regressor.add(Dropout(0.2))
regressor.add(SimpleRNN(units=50, activation='tanh', return_sequences=True))
regressor.add(Dropout(0.2))
regressor.add(SimpleRNN(units=50, activation='tanh', return_sequences=True))
regressor.add(Dropout(0.2))
regressor.add(SimpleRNN(units=50))
regressor.add(Dropout(0.2))
regressor.add(Dense(units=1))

regressor.compile(optimizer='adam', loss='mean_squared_error')
regressor.summary()

# Train the model
regressor.fit(X_train, y_train, epochs=100, batch_size=32)

# Prepare test set
past_60_days = data_training.tail(60)
df = pd.concat([past_60_days, data_test], ignore_index=True)
test_inputs = df.drop(['Date', 'Adj Close'], axis=1)
inputs_scaled = scaler.transform(test_inputs)

X_test = []
y_test = []
for i in range(60, inputs_scaled.shape[0]):
    X_test.append(inputs_scaled[i-60:i])
    y_test.append(inputs_scaled[i, 0])
X_test, y_test = np.array(X_test), np.array(y_test)

# Predict
y_pred = regressor.predict(X_test)
scale_factor = 1 / scaler.scale_[0]
y_pred_scaled = y_pred * scale_factor
y_test_scaled = y_test * scale_factor

# Metrics
mae = mean_absolute_error(y_test_scaled, y_pred_scaled)
mse = mean_squared_error(y_test_scaled, y_pred_scaled)
rmse = math.sqrt(mse)
r2 = r2_score(y_test_scaled, y_pred_scaled)

print(f"Mean Absolute Error (MAE): {mae:.4f}")
print(f"Mean Squared Error (MSE): {mse:.4f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.4f}")
print(f"RÂ² Score: {r2:.4f}")

# Plot
plt.figure(figsize=(14,5))
plt.plot(y_test_scaled, color='red', label='Real Google Stock Price')
plt.plot(y_pred_scaled, color='blue', label='Predicted Google Stock Price')
plt.title('Google Stock Price Prediction')
plt.xlabel('Time')
plt.ylabel('Google Stock Price')
plt.legend()
plt.show()
